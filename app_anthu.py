import streamlit as st
import pandas as pd
import numpy as np
import zipfile
import gc
import time
from pathlib import Path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é¡µé¢é…ç½®
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="MALDI-TOF MS è·¨ä»ªå™¨ç»Ÿä¸€å¤„ç†å¹³å°",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CSS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
    .main-header {
        font-size: 2.2rem;
        font-weight: 700;
        color: #1f77b4;
        margin-bottom: 0.4rem;
        text-align: center;
    }
    .sub-header {
        font-size: 1.05rem;
        color: #666;
        margin-bottom: 1.6rem;
        text-align: center;
    }
    .phase-header {
        background: linear-gradient(90deg, #1f77b4 0%, #4a9eff 100%);
        color: white;
        padding: 0.7rem 1rem;
        border-radius: 8px;
        margin: 0.8rem 0;
        font-size: 1.15rem;
        font-weight: 600;
    }
    .info-box {
        background: #f0f7ff;
        border-left: 4px solid #1f77b4;
        padding: 0.8rem 1rem;
        border-radius: 0 6px 6px 0;
        margin: 0.6rem 0;
        font-size: 0.92rem;
    }
    .warn-box {
        background: #fff8e1;
        border-left: 4px solid #ff9800;
        padding: 0.8rem 1rem;
        border-radius: 0 6px 6px 0;
        margin: 0.6rem 0;
        font-size: 0.92rem;
    }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# session state åˆå§‹åŒ–
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for key, default in {
    'template_cols': None,            # æœ€ç»ˆç»Ÿä¸€ç‰¹å¾åˆ—å list[str]
    'template_mz_values': None,       # å¯¹åº”çš„ mz æ•°å€¼ np.array
    'template_ready': False,
    'snr_threshold': 5,
    'align_tolerance': 5,
}.items():
    if key not in st.session_state:
        st.session_state[key] = default


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ ¸å¿ƒå‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_zip_txt(uploaded_zip) -> dict:
    """è§£æ ZIP â†’ {filename: raw_bytes}ï¼Œåªæå– .txt"""
    result = {}
    with zipfile.ZipFile(uploaded_zip, 'r') as z:
        for name in z.namelist():
            bn = Path(name).name
            if bn.lower().endswith('.txt') and not name.startswith('__MACOSX') and bn:
                result[bn] = z.read(name)
    return result


def read_anthu_txt(raw_bytes: bytes) -> pd.DataFrame:
    """
    è¯»å®‰å›¾å•ä¸ª txt â†’ DataFrame(mz, peak_height, peak_area, SNR, resolution)
    ç¼–ç  gbkï¼Œç¬¬1è¡Œè·¯å¾„ï¼Œç¬¬2è¡Œè¡¨å¤´ï¼Œç¬¬3è¡Œèµ·æ•°æ®
    """
    text = raw_bytes.decode('gbk', errors='replace')
    lines = text.splitlines()
    rows = []
    for line in lines[2:]:
        parts = [p.strip() for p in line.split('\t') if p.strip()]
        if len(parts) >= 5:
            try:
                rows.append([float(parts[0]), float(parts[1]),
                             float(parts[2]), float(parts[3]), float(parts[4])])
            except ValueError:
                continue
    return pd.DataFrame(rows, columns=['mz', 'peak_height', 'peak_area', 'SNR', 'resolution'])


def filter_anthu_peaks(df: pd.DataFrame, snr_threshold: int = 5) -> pd.DataFrame:
    """å®‰å›¾å³°è¡¨ç­›é€‰: SNR >= threshold ä¸” peak_area > 0"""
    mask = (df['SNR'] >= snr_threshold) & (df['peak_area'] > 0)
    return df[mask].reset_index(drop=True)


def anthu_to_feature_vector(peaks_df: pd.DataFrame,
                            template_mz: np.ndarray,
                            tolerance: float) -> np.ndarray:
    """
    å°†å•ä¸ªå®‰å›¾æ ·æœ¬çš„å³°è¡¨ï¼ŒæŒ‰æ¨¡æ¿ mz åˆ—è¡¨å’Œå®¹å·®å¯¹é½ â†’ ç‰¹å¾å‘é‡
    - æ¯ä¸ªæ¨¡æ¿ mz åœ¨å®‰å›¾å³°ä¸­æ‰¾è·ç¦» <= tolerance çš„æœ€è¿‘å³°ï¼Œå–å…¶ peak_height
    - æœªå‘½ä¸­åˆ™ä¸º 0
    - æœ€å TIC å½’ä¸€åŒ–ï¼ˆ/ sumï¼‰
    """
    n = len(template_mz)
    vec = np.zeros(n)

    if len(peaks_df) == 0:
        return vec

    atu_mz = peaks_df['mz'].values
    atu_height = peaks_df['peak_height'].values.astype(float)

    for i, tmz in enumerate(template_mz):
        diffs = np.abs(atu_mz - tmz)
        mask = diffs <= tolerance
        if mask.any():
            # å‘½ä¸­çš„å³°ä¸­å– peak_height æœ€å¤§çš„
            vec[i] = atu_height[mask].max()

    # TIC å½’ä¸€åŒ–
    s = vec.sum()
    if s > 0:
        vec = vec / s
    return vec


def build_unified_template(bruker_csv_df: pd.DataFrame,
                           all_anthu_peaks: list,
                           tolerance: float):
    """
    ä»¥å¸ƒé²å…‹ CSV çš„ç‰¹å¾åˆ—ä¸ºåŸºç¡€ï¼Œæ‰«ææ‰€æœ‰å®‰å›¾æ ·æœ¬çš„å³°ï¼Œ
    æ‰¾å‡ºæ— æ³•å¯¹é½åˆ°å¸ƒé²å…‹ä»»ä½•ç‰¹å¾çš„å³° â†’ å»é‡åè¿½åŠ ä¸ºæ–°ç‰¹å¾ã€‚
    è¿”å› (unified_cols: list[str], unified_mz: np.ndarray)
    """
    # å¸ƒé²å…‹å·²æœ‰çš„ mz
    brk_cols = [c for c in bruker_csv_df.columns if c.startswith('mz_')]
    brk_mz = np.array([float(c.replace('mz_', '')) for c in brk_cols])

    # æ”¶é›†æ‰€æœ‰å®‰å›¾å³°çš„ mz
    all_atu_mz = []
    for fn, peaks_df in all_anthu_peaks:
        all_atu_mz.extend(peaks_df['mz'].values.tolist())

    if len(all_atu_mz) == 0:
        return brk_cols, brk_mz

    all_atu_mz = np.array(all_atu_mz)

    # ç­›é€‰ï¼šå“ªäº›å®‰å›¾å³°å¯¹é½ä¸åˆ°å¸ƒé²å…‹çš„ä»»ä½•ç‰¹å¾
    new_mz_candidates = []
    for am in all_atu_mz:
        if len(brk_mz) == 0 or np.min(np.abs(brk_mz - am)) > tolerance:
            new_mz_candidates.append(am)

    if len(new_mz_candidates) == 0:
        return brk_cols, brk_mz

    # å¯¹æ–°å€™é€‰å³°å»é‡ï¼ˆè·ç¦» <= tolerance çš„èšä¸ºä¸€ç°‡ï¼Œå–ä¸­ä½æ•°ï¼‰
    new_mz_candidates = np.sort(new_mz_candidates)
    clusters = []
    current_cluster = [new_mz_candidates[0]]
    for mz in new_mz_candidates[1:]:
        if mz - current_cluster[-1] <= tolerance:
            current_cluster.append(mz)
        else:
            clusters.append(current_cluster)
            current_cluster = [mz]
    clusters.append(current_cluster)

    new_feature_mz = np.array([np.median(c) for c in clusters])

    # åˆå¹¶å¹¶æŒ‰ mz å‡åºæ’åˆ—
    all_mz = np.concatenate([brk_mz, new_feature_mz])
    sort_idx = np.argsort(all_mz)
    unified_mz = all_mz[sort_idx]
    unified_cols = [f"mz_{int(round(m))}" for m in unified_mz]

    return unified_cols, unified_mz


def bruker_csv_to_unified(bruker_csv_df: pd.DataFrame,
                          unified_mz: np.ndarray,
                          tolerance: float) -> np.ndarray:
    """
    å°†å¸ƒé²å…‹ CSV æ¯è¡Œæ˜ å°„åˆ°ç»Ÿä¸€æ¨¡æ¿ã€‚
    å¸ƒé²å…‹åŸæœ‰åˆ—æŒ‰æœ€è¿‘é‚»å¯¹é½ï¼Œæ–°å¢çš„å®‰å›¾åˆ—å¡« 0ã€‚
    æ•°å€¼ä¿æŒåŸæ ·ï¼ˆR å·²å¤„ç†å¥½ï¼‰ã€‚
    """
    brk_cols = [c for c in bruker_csv_df.columns if c.startswith('mz_')]
    brk_mz = np.array([float(c.replace('mz_', '')) for c in brk_cols])
    brk_values = bruker_csv_df[brk_cols].values.astype(float)

    n_samples = len(bruker_csv_df)
    n_unified = len(unified_mz)
    out = np.zeros((n_samples, n_unified))

    for j, bmz in enumerate(brk_mz):
        diffs = np.abs(unified_mz - bmz)
        nearest = np.argmin(diffs)
        if diffs[nearest] <= tolerance:
            out[:, nearest] = brk_values[:, j]

    return out


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¾§è¾¹æ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.header("âš™ï¸ å¤„ç†å‚æ•°")
    st.markdown('<div class="info-box">å‚æ•°å¯¹<b>å®‰å›¾æ•°æ®å¤„ç†</b>ç”Ÿæ•ˆï¼›<br>å¸ƒé²å…‹æ•°æ®å·²æ˜¯å¤„ç†å¥½çš„ CSVï¼Œç›´æ¥è¯»å…¥ã€‚</div>', unsafe_allow_html=True)

    snr_threshold = st.slider(
        "å®‰å›¾ SNR é˜ˆå€¼", min_value=3, max_value=15, value=5,
        help="å®‰å›¾å³°è¡¨ä¸­ SNR < æ­¤å€¼çš„å³°ä¼šè¢«ä¸¢å¼ƒ"
    )
    align_tolerance = st.slider(
        "è·¨ä»ªå™¨å¯¹é½å®¹å·® (Da)", min_value=1, max_value=15, value=5,
        help="å®‰å›¾å³°ä¸æ¨¡æ¿ç‰¹å¾ mz ä¹‹é—´çš„æœ€å¤§å…è®¸åå·®ã€‚è¶…å‡ºæ­¤èŒƒå›´çš„å³°ä¼šä½œä¸ºæ–°ç‰¹å¾è¿½åŠ ï¼ˆé˜¶æ®µ1ï¼‰æˆ–ç›´æ¥å¿½ç•¥ï¼ˆé˜¶æ®µ2ï¼‰"
    )

    st.session_state.snr_threshold = snr_threshold
    st.session_state.align_tolerance = align_tolerance

    st.divider()
    st.header("ğŸ’¾ å†…å­˜ç®¡ç†")
    if st.button("ğŸ§¹ æ¸…ç†ç¼“å­˜ï¼ˆä¿ç•™æ¨¡æ¿ï¼‰", use_container_width=True):
        keys_to_keep = {'template_cols', 'template_mz_values', 'template_ready',
                        'snr_threshold', 'align_tolerance'}
        for k in list(st.session_state.keys()):
            if k not in keys_to_keep:
                del st.session_state[k]
        gc.collect()
        st.success("å·²æ¸…ç†")
        st.rerun()
    if st.button("ğŸ—‘ï¸ å®Œå…¨æ¸…ç©º", use_container_width=True):
        st.session_state.clear()
        gc.collect()
        st.success("å·²æ¸…ç©º")
        st.rerun()

    st.divider()
    st.header("ğŸ“– æµç¨‹è¯´æ˜")
    st.markdown("""
    **é˜¶æ®µ1ï¼ˆè®­ç»ƒé›†ï¼‰ï¼š**
    - ä¸Šä¼ å¸ƒé²å…‹å·²å¤„ç†çš„ CSVï¼ˆå« group åˆ— + mz ç‰¹å¾åˆ—ï¼‰
    - ä¸Šä¼ å®‰å›¾ txt çš„ ZIP
    - ä»¥å¸ƒé²å…‹ç‰¹å¾ä¸ºåŸºç¡€ï¼Œå®‰å›¾å³°æŒ‰å®¹å·®å¯¹é½ï¼›
      å¯¹é½ä¸åˆ°çš„å®‰å›¾å³°è¿½åŠ ä¸ºæ–°ç‰¹å¾
    - è¾“å‡ºï¼šç»Ÿä¸€ç‰¹å¾çŸ©é˜µ + ç‰¹å¾æ¨¡æ¿

    **é˜¶æ®µ2ï¼ˆéªŒè¯é›†ï¼‰ï¼š**
    - åªéœ€ä¸Šä¼ å®‰å›¾ txt çš„ ZIP
    - ç”¨é˜¶æ®µ1çš„æ¨¡æ¿å¯¹é½ï¼Œè¾“å‡ºç»´åº¦ä¸è®­ç»ƒé›†ä¸€è‡´
    - æ¨¡æ¿ä¹‹å¤–çš„å³°è‡ªåŠ¨å¿½ç•¥
    """)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸»ç•Œé¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown('<div class="main-header">ğŸ”¬ MALDI-TOF MS è·¨ä»ªå™¨ç»Ÿä¸€å¤„ç†å¹³å°</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">å¸ƒé²å…‹ CSV + å®‰å›¾ TXT â†’ ç»Ÿä¸€ç‰¹å¾çŸ©é˜µ</div>', unsafe_allow_html=True)

tab1, tab2 = st.tabs(["ğŸ¯ é˜¶æ®µ1: è®­ç»ƒé›† â†’ å»ºç«‹æ¨¡æ¿", "ğŸ”„ é˜¶æ®µ2: éªŒè¯é›† â†’ åº”ç”¨æ¨¡æ¿"])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é˜¶æ®µ1
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab1:
    st.markdown('<div class="phase-header">ğŸ“Š é˜¶æ®µ1: è®­ç»ƒé›†å¤„ç†ï¼Œå»ºç«‹ç»Ÿä¸€ç‰¹å¾æ¨¡æ¿</div>', unsafe_allow_html=True)
    st.markdown("""<div class="info-box">
    <b>å¸ƒé²å…‹</b>ï¼šä¸Šä¼ ä¹‹å‰ç”¨ R å¤„ç†å¥½çš„ CSVï¼ˆéœ€å« <code>group</code> åˆ—å’Œ <code>mz_xxxx</code> ç‰¹å¾åˆ—ï¼‰<br>
    <b>å®‰å›¾</b>ï¼šä¸Šä¼ åŒ…å«æ‰€æœ‰ txt çš„ ZIP å‹ç¼©åŒ…<br>
    ç³»ç»Ÿä¼šè‡ªåŠ¨å°†ä¸¤è€…å¯¹é½åˆ°ç»Ÿä¸€çš„ç‰¹å¾ç©ºé—´ã€‚
    </div>""", unsafe_allow_html=True)

    # â”€â”€ ä¸Šä¼ åŒº â”€â”€
    col_brk, col_atu = st.columns(2)
    with col_brk:
        brk_csv_upload = st.file_uploader("ğŸ“ å¸ƒé²å…‹ CSV", type=['csv'], key='brk_csv',
                                          help="R å¤„ç†åçš„å³°å¼ºåº¦çŸ©é˜µ")
    with col_atu:
        atu_zip_upload = st.file_uploader("ğŸ“ å®‰å›¾ ZIP", type=['zip'], key='atu_zip',
                                          help="åŒ…å«æ‰€æœ‰å®‰å›¾ txt çš„å‹ç¼©åŒ…")

    # â”€â”€ é¢„æ£€æŸ¥ â”€â”€
    brk_df = None
    atu_files = {}

    if brk_csv_upload:
        brk_df = pd.read_csv(brk_csv_upload)
        brk_mz_cols = [c for c in brk_df.columns if c.startswith('mz_')]
        has_group = 'group' in brk_df.columns

        st.success(f"âœ… å¸ƒé²å…‹ CSV è¯»å…¥æˆåŠŸ")
        c1, c2, c3 = st.columns(3)
        c1.metric("æ ·æœ¬æ•°", len(brk_df))
        c2.metric("ç‰¹å¾æ•°", len(brk_mz_cols))
        c3.metric("å« group åˆ—", "âœ… æ˜¯" if has_group else "âŒ å¦")

    if atu_zip_upload:
        atu_files = extract_zip_txt(atu_zip_upload)
        st.success(f"âœ… å®‰å›¾ ZIP è¯»å…¥æˆåŠŸï¼š{len(atu_files)} ä¸ª txt")

    # â”€â”€ å¤„ç†æŒ‰é’® â”€â”€
    can_run = (brk_df is not None) and (len(atu_files) > 0)
    if not can_run:
        st.markdown('<div class="warn-box">âš ï¸ è¯·åŒæ—¶ä¸Šä¼ å¸ƒé²å…‹ CSV å’Œå®‰å›¾ ZIP æ‰èƒ½å¼€å§‹å¤„ç†ã€‚</div>', unsafe_allow_html=True)

    if can_run and st.button("ğŸ¯ å¼€å§‹å¤„ç†è®­ç»ƒé›†", type="primary", use_container_width=True):

        progress = st.progress(0)
        status = st.empty()
        tolerance = st.session_state.align_tolerance
        snr_thresh = st.session_state.snr_threshold

        # â”€â”€ Step 1: è¯»å–å¹¶ç­›é€‰æ‰€æœ‰å®‰å›¾å³° â”€â”€
        status.text("ğŸ“– Step 1/4: è¯»å–å®‰å›¾ txt å¹¶ç­›é€‰å³°...")
        progress.progress(5)

        all_anthu_peaks = []
        atu_read_info = []
        for fn, raw in atu_files.items():
            raw_df = read_anthu_txt(raw)
            filt_df = filter_anthu_peaks(raw_df, snr_thresh)
            all_anthu_peaks.append((fn, filt_df))
            atu_read_info.append((fn, len(raw_df), len(filt_df)))

        progress.progress(15)

        # â”€â”€ Step 2: æ„å»ºç»Ÿä¸€æ¨¡æ¿ â”€â”€
        status.text("ğŸ”— Step 2/4: æ„å»ºç»Ÿä¸€ç‰¹å¾æ¨¡æ¿...")

        unified_cols, unified_mz = build_unified_template(brk_df, all_anthu_peaks, tolerance)
        n_brk_features = len([c for c in brk_df.columns if c.startswith('mz_')])
        n_new_features = len(unified_cols) - n_brk_features

        progress.progress(30)

        # â”€â”€ Step 3: å¸ƒé²å…‹ â†’ ç»Ÿä¸€çŸ©é˜µ â”€â”€
        status.text("ğŸ“Š Step 3/4: æ˜ å°„å¸ƒé²å…‹å’Œå®‰å›¾åˆ°ç»Ÿä¸€ç‰¹å¾çŸ©é˜µ...")

        brk_matrix = bruker_csv_to_unified(brk_df, unified_mz, tolerance)
        brk_out = pd.DataFrame(brk_matrix, columns=unified_cols)
        brk_out.insert(0, 'sample',
                       brk_df['group'].astype(str).values if 'group' in brk_df.columns
                       else [f"bruker_{i}" for i in range(len(brk_df))])
        brk_out.insert(1, 'instrument', 'bruker')

        progress.progress(55)

        # â”€â”€ Step 4: å®‰å›¾ â†’ ç»Ÿä¸€çŸ©é˜µ â”€â”€
        atu_rows = []
        for fn, filt_df in all_anthu_peaks:
            vec = anthu_to_feature_vector(filt_df, unified_mz, tolerance)
            atu_rows.append(vec)

        atu_out = pd.DataFrame(np.vstack(atu_rows), columns=unified_cols)
        atu_out.insert(0, 'sample', [r[0] for r in all_anthu_peaks])
        atu_out.insert(1, 'instrument', 'anthu')

        progress.progress(75)

        # â”€â”€ åˆå¹¶ â”€â”€
        status.text("ğŸ“¦ Step 4/4: åˆå¹¶è¾“å‡º...")
        combined = pd.concat([brk_out, atu_out], ignore_index=True)

        # ä¿å­˜æ¨¡æ¿åˆ° session
        st.session_state.template_cols = unified_cols
        st.session_state.template_mz_values = unified_mz
        st.session_state.template_ready = True

        progress.progress(100)
        status.text("âœ… å®Œæˆï¼")
        time.sleep(0.4)
        progress.empty()
        status.empty()

        # â•â•â• ç»“æœå±•ç¤º â•â•â•
        st.success("âœ… è®­ç»ƒé›†å¤„ç†å®Œæˆï¼Œç»Ÿä¸€ç‰¹å¾æ¨¡æ¿å·²å»ºç«‹ï¼")

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("æ€»æ ·æœ¬æ•°", len(combined))
        c2.metric("ç»Ÿä¸€ç‰¹å¾æ•°", len(unified_cols))
        c3.metric("å¸ƒé²å…‹åŸæœ‰ç‰¹å¾", n_brk_features)
        c4.metric("å®‰å›¾æ–°å¢ç‰¹å¾", n_new_features)

        c1, c2 = st.columns(2)
        c1.metric("å¸ƒé²å…‹æ ·æœ¬æ•°", len(brk_out))
        c2.metric("å®‰å›¾æ ·æœ¬æ•°", len(atu_out))

        # å®‰å›¾æ–‡ä»¶æ˜ç»†
        st.subheader("ğŸ“‹ å®‰å›¾æ–‡ä»¶æ˜ç»†")
        info_df = pd.DataFrame(atu_read_info,
                               columns=['æ–‡ä»¶å', 'åŸå§‹å³°æ•°', f'ç­›é€‰åå³°æ•°(SNRâ‰¥{snr_thresh})'])
        st.dataframe(info_df, use_container_width=True, hide_index=True)

        # å¯¹é½è¯¦æƒ…
        with st.expander("ğŸ”— å¯¹é½è¯¦æƒ…ï¼ˆæ–°å¢ç‰¹å¾åˆ—è¡¨ï¼‰"):
            brk_mz_arr = np.array([float(c.replace('mz_', '')) for c in brk_df.columns if c.startswith('mz_')])
            new_features_info = []
            for col, mz in zip(unified_cols, unified_mz):
                if len(brk_mz_arr) == 0 or np.min(np.abs(brk_mz_arr - mz)) > tolerance:
                    new_features_info.append({'æ–°å¢ç‰¹å¾': col, 'mzå€¼': f"{mz:.1f}", 'æ¥æº': 'å®‰å›¾ç‹¬æœ‰'})
            if new_features_info:
                st.dataframe(pd.DataFrame(new_features_info), use_container_width=True, hide_index=True)
            else:
                st.info("æ‰€æœ‰å®‰å›¾å³°å‡å·²å¯¹é½åˆ°å¸ƒé²å…‹ç‰¹å¾ï¼Œæ— æ–°å¢åˆ—ã€‚")

        # ç‰¹å¾çŸ©é˜µé¢„è§ˆ
        with st.expander("ğŸ“Š åˆå¹¶ç‰¹å¾çŸ©é˜µé¢„è§ˆï¼ˆå‰12åˆ—ï¼‰"):
            preview_cols = ['sample', 'instrument'] + unified_cols[:10]
            st.dataframe(combined[preview_cols].round(6), use_container_width=True, hide_index=True)

        # â”€â”€ ä¸‹è½½ â”€â”€
        st.divider()
        st.subheader("ğŸ“¥ ä¸‹è½½")
        c1, c2 = st.columns(2)

        export_cols = ['sample'] + unified_cols
        c1.download_button(
            "ğŸ“Š è®­ç»ƒé›†ç»Ÿä¸€ç‰¹å¾çŸ©é˜µ CSV",
            data=combined[export_cols].to_csv(index=False),
            file_name="train_feature_matrix_unified.csv",
            mime="text/csv",
            use_container_width=True
        )

        template_export = pd.DataFrame({
            'feature_name': unified_cols,
            'mz_value': unified_mz.round(1)
        })
        c2.download_button(
            "ğŸ¯ ç‰¹å¾æ¨¡æ¿ CSV",
            data=template_export.to_csv(index=False),
            file_name="feature_template.csv",
            mime="text/csv",
            use_container_width=True
        )

        del combined, brk_out, atu_out, brk_matrix
        gc.collect()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é˜¶æ®µ2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab2:
    st.markdown('<div class="phase-header">ğŸ”„ é˜¶æ®µ2: éªŒè¯é›†å¤„ç†ï¼ˆä½¿ç”¨è®­ç»ƒé›†æ¨¡æ¿ï¼‰</div>', unsafe_allow_html=True)

    if not st.session_state.template_ready:
        st.markdown('<div class="warn-box">âš ï¸ è¯·å…ˆå®Œæˆé˜¶æ®µ1ï¼Œå»ºç«‹ç‰¹å¾æ¨¡æ¿åæ‰èƒ½å¤„ç†éªŒè¯é›†ã€‚</div>', unsafe_allow_html=True)
    else:
        unified_cols = st.session_state.template_cols
        unified_mz = st.session_state.template_mz_values

        st.success(f"âœ… ç‰¹å¾æ¨¡æ¿å°±ç»ªï¼š{len(unified_cols)} ä¸ªç‰¹å¾")
        st.markdown("""<div class="info-box">
        ä¸Šä¼ å®‰å›¾ txt çš„ ZIPï¼Œç³»ç»ŸæŒ‰è®­ç»ƒé›†æ¨¡æ¿å¯¹é½ï¼Œè¾“å‡ºä¸è®­ç»ƒé›†<b>ç»´åº¦å®Œå…¨ä¸€è‡´</b>çš„ç‰¹å¾çŸ©é˜µã€‚<br>
        æ¨¡æ¿ä¹‹å¤–çš„å³°è‡ªåŠ¨å¿½ç•¥ï¼›å¸ƒé²å…‹ç‹¬æœ‰çš„é«˜ mz ç‰¹å¾åœ¨å®‰å›¾æ ·æœ¬ä¸­å¡« 0ã€‚
        </div>""", unsafe_allow_html=True)

        valid_zip_upload = st.file_uploader("ğŸ“ å®‰å›¾éªŒè¯é›† ZIP", type=['zip'], key='valid_zip')

        if valid_zip_upload:
            valid_files = extract_zip_txt(valid_zip_upload)
            if not valid_files:
                st.error("ZIP ä¸­æ²¡æœ‰æ‰¾åˆ° .txt æ–‡ä»¶")
            else:
                st.success(f"âœ… æ‰¾åˆ° {len(valid_files)} ä¸ª txt æ–‡ä»¶")

                if st.button("ğŸ”„ å¼€å§‹å¤„ç†éªŒè¯é›†", type="primary", use_container_width=True):
                    progress = st.progress(0)
                    status = st.empty()
                    tolerance = st.session_state.align_tolerance
                    snr_thresh = st.session_state.snr_threshold

                    status.text("ğŸ“– è¯»å–å¹¶å¤„ç†å®‰å›¾ txt...")
                    progress.progress(10)

                    valid_rows = []
                    valid_info = []
                    total = len(valid_files)

                    for i, (fn, raw) in enumerate(valid_files.items()):
                        raw_df = read_anthu_txt(raw)
                        filt_df = filter_anthu_peaks(raw_df, snr_thresh)
                        vec = anthu_to_feature_vector(filt_df, unified_mz, tolerance)
                        valid_rows.append(vec)
                        valid_info.append((fn, len(raw_df), len(filt_df)))
                        progress.progress(10 + int(75 * (i + 1) / total))

                    status.text("ğŸ“¦ æ„å»ºè¾“å‡ºçŸ©é˜µ...")

                    valid_df = pd.DataFrame(np.vstack(valid_rows), columns=unified_cols)
                    valid_df.insert(0, 'sample', [r[0] for r in valid_info])
                    valid_df.insert(1, 'instrument', 'anthu')

                    progress.progress(100)
                    status.text("âœ… å®Œæˆï¼")
                    time.sleep(0.4)
                    progress.empty()
                    status.empty()

                    # â•â•â• ç»“æœå±•ç¤º â•â•â•
                    st.success("âœ… éªŒè¯é›†å¤„ç†å®Œæˆï¼ç‰¹å¾ç»´åº¦ä¸è®­ç»ƒé›†ä¸€è‡´ï¼")

                    c1, c2, c3 = st.columns(3)
                    c1.metric("æ ·æœ¬æ•°", len(valid_df))
                    c2.metric("ç‰¹å¾æ•°", len(unified_cols))
                    c3.metric("ç‰¹å¾ä¸€è‡´æ€§", "âœ… ä¸è®­ç»ƒé›†ä¸€è‡´")

                    # æ–‡ä»¶æ˜ç»†
                    st.subheader("ğŸ“‹ æ–‡ä»¶æ˜ç»†")
                    info_df = pd.DataFrame(valid_info,
                                           columns=['æ–‡ä»¶å', 'åŸå§‹å³°æ•°', f'ç­›é€‰åå³°æ•°(SNRâ‰¥{snr_thresh})'])
                    st.dataframe(info_df, use_container_width=True, hide_index=True)

                    # éé›¶ç‰¹å¾ç»Ÿè®¡
                    feat_data = valid_df[unified_cols].astype(float)
                    nonzero_counts = (feat_data > 0).sum(axis=1)
                    with st.expander("ğŸ“Š å„æ ·æœ¬éé›¶ç‰¹å¾æ•°ä¸è¦†ç›–ç‡"):
                        nz_df = pd.DataFrame({
                            'æ–‡ä»¶å': valid_df['sample'].values,
                            'éé›¶ç‰¹å¾æ•°': nonzero_counts.values,
                            'è¦†ç›–ç‡': (nonzero_counts / len(unified_cols) * 100).round(1).astype(str) + '%'
                        })
                        st.dataframe(nz_df, use_container_width=True, hide_index=True)

                    # é¢„è§ˆ
                    with st.expander("ğŸ“Š ç‰¹å¾çŸ©é˜µé¢„è§ˆï¼ˆå‰10åˆ—ï¼‰"):
                        preview_cols = ['sample'] + unified_cols[:10]
                        st.dataframe(valid_df[preview_cols].round(6), use_container_width=True, hide_index=True)

                    # â”€â”€ ä¸‹è½½ â”€â”€
                    st.divider()
                    export_cols = ['sample'] + unified_cols
                    st.download_button(
                        "ğŸ“Š ä¸‹è½½éªŒè¯é›†ç‰¹å¾çŸ©é˜µ CSV",
                        data=valid_df[export_cols].to_csv(index=False),
                        file_name="valid_feature_matrix_unified.csv",
                        mime="text/csv",
                        use_container_width=True
                    )

                    del valid_df, feat_data
                    gc.collect()


# â”€â”€ åº•éƒ¨ â”€â”€
st.divider()
st.markdown("<div style='text-align:center;color:#aaa;font-size:0.85rem;'>MALDI-TOF MS è·¨ä»ªå™¨ç»Ÿä¸€å¤„ç†å¹³å° Â· å¸ƒé²å…‹ CSV + å®‰å›¾ TXT</div>", unsafe_allow_html=True)
